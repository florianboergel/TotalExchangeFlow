{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp tef_core\n",
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import math\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    filename=\"logger.TEF.GETM\",\n",
    "                    filemode=\"w\",\n",
    "                    format=\"%(asctime)-15s %(levelname)-8s %(message)s\")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TEF_object():\n",
    "\n",
    "    def __init__(self, filename = None, ds = None, **kwargs):\n",
    "\n",
    "        # What happens if no filename is provided\n",
    "        if not filename:\n",
    "            if ds is None:\n",
    "                self.ds = None\n",
    "            else:\n",
    "                self.ds = ds\n",
    "            return\n",
    "\n",
    "        # continue with filename\n",
    "        try:\n",
    "            self.ds = None\n",
    "            self.read(filename, **kwargs)\n",
    "        except (OSError, IOError, RuntimeError):\n",
    "            try:\n",
    "                self.read(filename, **kwargs)\n",
    "            except Exception:\n",
    "                raise IOError(\"Unkown file format. Known formats are netcdf.\")\n",
    "\n",
    "        self.flux = None\n",
    "\n",
    "    def __repr__(self):\n",
    "        try:\n",
    "            string = \"xarray dataset with {} time steps \\n\" \\\n",
    "                     \"Available fields: {}\".format(\n",
    "                self.timesteps, \", \".join(self.variables)\n",
    "            )\n",
    "        except AttributeError:\n",
    "            string = \"Empty TEF object \\n\" \\\n",
    "                     \"Hint: Have you used read() to load data?\"\n",
    "        return string\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'Class {}: \\n'.format(self.__class__.__name__, self.ds)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getattr__(self, attr):\n",
    "        if attr in self.__dict__:\n",
    "            return getattr(self, attr)\n",
    "        return getattr(self.ds, attr)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self.ds[key]\n",
    "\n",
    "    @property\n",
    "    def timesteps(self):\n",
    "        if len(self.ds.dims) != 3:\n",
    "            logger.warning(\n",
    "                \"\\nDimensions should be equal to 3, but they are not.\\n\"\n",
    "                \"You want ... \"\n",
    "            )\n",
    "            return self.ds.dims[self._get_name_time()]\n",
    "        return self.ds.dims[self.get_name_time()]\n",
    "\n",
    "    @property\n",
    "    def variables(self):\n",
    "        return list(self.ds.data_vars)\n",
    "\n",
    "    @property\n",
    "    def dimensions(self):\n",
    "        return list(self.ds.dims)\n",
    "\n",
    "    def read(self, filename,  **kwargs):\n",
    "        if self.ds is None:\n",
    "            self.ds = xr.open_dataset(filename, **kwargs)\n",
    "            logger.debug(\"read: {}\".format(self.__str__))\n",
    "        else:\n",
    "            raise ValueError(\"TEF object is already set!\")\n",
    "\n",
    "    def set_up(self,\n",
    "           time_name=None,\n",
    "           longitude_name=None,\n",
    "           latitude_name=None,\n",
    "           depth_name=None):\n",
    "\n",
    "        # set dimensions\n",
    "        if time_name is None:\n",
    "            self._time_name = self._get_name_time()\n",
    "        else:\n",
    "            self._time_name = time_name\n",
    "        if longitude_name is None:\n",
    "            self._longitude_name = self._get_name_longitude()\n",
    "        else:\n",
    "            self._longitude_name = longitude_name\n",
    "\n",
    "        if latitude_name is None:\n",
    "            self._latitude_name = self._get_name_latitude()\n",
    "        else:\n",
    "            self._latitude_name = latitude_name\n",
    "\n",
    "        if depth_name is None:\n",
    "            self._depth_name = self._get_name_depth()\n",
    "        else:\n",
    "            self._depth_name = depth_name\n",
    "\n",
    "        if time_name is None:\n",
    "            self._time_name = self._get_name_time()\n",
    "        else:\n",
    "            self._time_name = time_name\n",
    "\n",
    "        # Transpose data\n",
    "        self.ds = self.ds.transpose(self._time_name,\n",
    "                                    self._depth_name,\n",
    "                                    self._latitude_name,\n",
    "                                    self._longitude_name)\n",
    "\n",
    "    def _get_name_time(self):\n",
    "        \"\"\"\n",
    "        check for 'time' dimension and return name\n",
    "        \"\"\"\n",
    "        # check unit\n",
    "        for dim in self.ds.dims:\n",
    "            if (('units' in self.ds[dim].attrs and\n",
    "                'since' in self.ds[dim].attrs['units']) or\n",
    "                ('units' in self.ds[dim].encoding and\n",
    "                 'since' in self.ds[dim].encoding['units']) or\n",
    "                dim in ['time']):\n",
    "                return dim\n",
    "        # check dtype\n",
    "        for dim in self.ds.variables:\n",
    "            try:\n",
    "                var = self.ds[dim].data[0]\n",
    "            except IndexError:\n",
    "                var = self.ds[dim].data\n",
    "            if isinstance(var, \"datetime64\"):\n",
    "                return dim\n",
    "        # no 'time' dimension found\n",
    "        logger.warning(\n",
    "            \"\\n 'time' dimension (dtype='datetime64[ns]') not found.\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "    def _get_name_longitude(self):\n",
    "        \"\"\"\n",
    "        check for 'longitude' dimension and return name\n",
    "        \"\"\"\n",
    "        for dim in self.ds.dims:\n",
    "            if (('units' in self.ds[dim].attrs and\n",
    "               self.ds[dim].attrs['units'] in ['degree_east', 'degrees_east']) or\n",
    "               dim in ['lon', 'longitude', 'x']):\n",
    "               return dim\n",
    "        # no 'longitude' dimension found\n",
    "        logger.warning(\n",
    "            \"\\n 'longitude' dimension (unit='degrees_east') not found.\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "\n",
    "    def _get_name_latitude(self):\n",
    "        \"\"\"\n",
    "        check for 'latitude' dimension and return name\n",
    "        \"\"\"\n",
    "        for dim in self.ds.dims:\n",
    "            if (('units' in self.ds[dim].attrs  and\n",
    "                self.ds[dim].attrs['units'] in ['degree_north', 'degrees_north']) or\n",
    "                dim in ['lat', 'latitude', 'y']):\n",
    "                return dim\n",
    "        # no 'latitude' dimension found\n",
    "        logger.warning(\n",
    "            \"\\n 'latitude' dimension (unit='degrees_north') not found.\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "    def _get_name_depth(self):\n",
    "        \"\"\"\n",
    "        check for 'latitude' dimension and return name\n",
    "        \"\"\"\n",
    "        for dim in self.ds.dims:\n",
    "            if (('units' in self.ds[dim].attrs  and\n",
    "                self.ds[dim].attrs['units'] in ['vertical', 'level']) or\n",
    "                dim in ['level', 'depth']):\n",
    "                return dim\n",
    "        # no 'latitude' dimension found\n",
    "        logger.warning(\n",
    "            \"\\n 'depth not found\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "    def calc_volume_transport(self, vel, height, delta):\n",
    "        self.volume_transport = vel*height*delta\n",
    "    \n",
    "    def calc_salt_transport(self, salt, vel, height, delta):\n",
    "        self.salt_transport = salt*vel*height*delta\n",
    "\n",
    "    def sort_1dim(self, sort_by_variable = None, transport = None, N = None, minmaxrange = None):\n",
    "        if sort_by_variable is None:\n",
    "            raise ValueError(\"Please define a variable that you want to sort by.\")\n",
    "        if transport is None:\n",
    "            raise ValueError(\"Please provided transport term or calculate transport by using calc_volume_transport()\")\n",
    "\n",
    "        if minmaxrange is None:\n",
    "            varmin = np.floor(sort_by_variable.min().values)\n",
    "            varmax = np.ceil(sort_by_variable.max().values)\n",
    "            logger.info(\"Using minimum and maximum of the data to construct sorting array\")\n",
    "        else:\n",
    "            if minmaxrange[0] > sort_by_variable.min().values:\n",
    "                print(\"Warning: Given minimum value is greater than the minimum value of the variable.\")\n",
    "                print(\"Warning: Given {}, minmum value of variable {}\".format(minmaxrange[0],\n",
    "                                                                     sort_by_variable.min().values))\n",
    "            if minmaxrange[-1] < sort_by_variable.max().values:\n",
    "                print(\"Warning: Given maximum value is smaller than the maximum value of the variable.\")\n",
    "                print(\"Warning: Given {}, maximum value of variable {}\".format(minmaxrange[-1],\n",
    "                                                                     sort_by_variable.max().values))\n",
    "            if type(minmaxrange) != \"numpy.ndarray\" and type(minmaxrange) is not tuple:\n",
    "                print(\"Please provide array range, e.g. np.arange(0,10), or a tuple, e.g. (0,10).\")\n",
    "            \n",
    "            else:\n",
    "                varmin = minmaxrange[0]\n",
    "                varmax = minmaxrange[-1]\n",
    "\n",
    "        if N is None:\n",
    "            N = 1024\n",
    "            logger.info(\"Setting N to default value of 1024\")\n",
    "\n",
    "        if type(minmaxrange) == \"numpy.ndarray\":\n",
    "            print('Using provided numpy array')\n",
    "\n",
    "            var_q = minmaxrange\n",
    "            \n",
    "            #check if equidistant\n",
    "            diff=np.diff(np.diff(var_q))\n",
    "            if len(diff[diff!=0]) != 0:\n",
    "                print('Warning: Provided array is not equidistant, but the function assumes equidistance!')\n",
    "            delta_var=var_q[1]-var_q[0]\n",
    "            \n",
    "            var_Q = np.arange(var_q-0.5*delta_var, var_q[-1]+0.5*delta_var, delta_var)\n",
    "        else:\n",
    "            delta_var = ((varmax-varmin)/N)\n",
    "\n",
    "            var_q = np.arange(varmin + 0.5*delta_var,\n",
    "                              varmax+0.5*delta_var,\n",
    "                              delta_var)\n",
    "\n",
    "            var_Q = np.arange(varmin, varmax+delta_var, delta_var)\n",
    "\n",
    "        idx = xr.apply_ufunc(np.digitize, sort_by_variable-0.5*delta_var, var_q)+1 #plus + has to be deleted, just for comapring atm\n",
    "        \n",
    "        #print('salt',sort_by_variable[100,20,:,0])\n",
    "        #print('flux',transport[100,20,:,0])\n",
    "        sort_by_variable = np.ma.masked_invalid(sort_by_variable)\n",
    "        idx_old=(sort_by_variable-varmin)/delta_var #compute the index in which the flux will be stored\n",
    "        idx_old=idx_old.astype(int)+1\n",
    "        \n",
    "        print(idx.shape,idx_old.shape)\n",
    "        print('salt_value',sort_by_variable[20,:,0])\n",
    "        print('idx',idx[20,:,0])\n",
    "        print('idx_old',idx_old[20,:,0])\n",
    "        print(idx.max(),idx_old.max())\n",
    "\n",
    "        #print(transport)\n",
    "        if len(transport.time.shape)==0:\n",
    "            #no time dimension\n",
    "            out_q = np.zeros((N,))\n",
    "            \n",
    "            for i in range(N):\n",
    "                out_q[i] = transport.where(idx == i).sum([self._get_name_depth(),\n",
    "                                                     self._get_name_latitude(),\n",
    "                                                     self._get_name_longitude()]) / delta_var\n",
    "\n",
    "            out_Q = np.zeros((N+1,))\n",
    "\n",
    "            for i in range(N):\n",
    "                out_Q[i] = np.sum(out_q[i:] * delta_var)\n",
    "\n",
    "\n",
    "            out = xr.Dataset({\n",
    "            \"q\": ([\"var_q\"], out_q),\n",
    "            \"Q\": ([\"var_Q\"], out_Q)},\n",
    "            coords={\n",
    "                \"var_q\": ([\"var_q\"],var_q),\n",
    "                \"var_Q\": ([\"var_Q\"], var_Q),\n",
    "            })\n",
    "\n",
    "            \n",
    "        else:\n",
    "            out_q = np.zeros((self.timesteps,N))\n",
    "\n",
    "            for i in range(N):\n",
    "                out_q[:, i] = transport.where(idx == i).sum([self._get_name_depth(),\n",
    "                                                     self._get_name_latitude(),\n",
    "                                                     self._get_name_longitude()]) / delta_var\n",
    "\n",
    "            out_Q = np.zeros((self.timesteps, N+1))\n",
    "\n",
    "            for i in range(N):\n",
    "                out_Q[:, i] = np.sum(out_q[:, i:] * delta_var)\n",
    "\n",
    "\n",
    "            out = xr.Dataset({\n",
    "            \"q\": ([\"time\", \"var_q\"], out_q),\n",
    "            \"Q\": ([\"time\", \"var_Q\"], out_Q)},\n",
    "            coords={\n",
    "                \"time\": ([\"time\"], self.ds[self._get_name_time()]),\n",
    "                \"var_q\": ([\"var_q\"],var_q),\n",
    "                \"var_Q\": ([\"var_Q\"], var_Q),\n",
    "            })\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def sort_2dim(self, sort_by_variable = None,\n",
    "                        sort_by_variable2 = None,\n",
    "                        flux = None,\n",
    "                        N = None,\n",
    "                        minmaxrange = None,\n",
    "                        minmaxrange2 = None):\n",
    "\n",
    "            if sort_by_variable is None:\n",
    "                raise ValueError(\"Please define a variable that you want to sort by.\")\n",
    "            if sort_by_variable2 is None:\n",
    "                raise ValueError(\"Please define a second variable that you want to sort by.\")    \n",
    "\n",
    "            if flux is None:\n",
    "                raise ValueError(\"Please provided flux term or calculate flux by using calc_flux()\")\n",
    "\n",
    "            if minmaxrange is None:\n",
    "                varmin = np.floor(sort_by_variable.min().values)\n",
    "                varmax = np.ceil(sort_by_variable.max().values)      \n",
    "            else:\n",
    "                if minmaxrange[0] > sort_by_variable.min().values:\n",
    "                    print(\"Warning: Given minimum value is gretaer than the minimum value of the variable.\")\n",
    "                    print(\"Warning: Given {}, minmum value of variable {}\".format(minmaxrange[0],\n",
    "                                                                         sort_by_variable.min().values))\n",
    "                if minmaxrange[-1] < sort_by_variable.max().values:\n",
    "                    print(\"Warning: Given maximum value is smaller than the maximum value of the variable.\")\n",
    "                    print(\"Warning: Given {}, maximum value of variable {}\".format(minmaxrange[-1],\n",
    "                                                                         sort_by_variable.max().values))\n",
    "                if type(minmaxrange) != \"numpy.ndarray\" and type(minmaxrange) is not tuple:\n",
    "                    print(\"Please provide array range, e.g. np.arange(0,10), or a tuple, e.g. (0,10).\")\n",
    "                else: \n",
    "                    varmin = minmaxrange[0]\n",
    "                    varmax = minmaxrange[-1]\n",
    "\n",
    "            if minmaxrange2 is None:\n",
    "                varmin2 = np.floor(sort_by_variable2.min().values)\n",
    "                varmax2 = np.ceil(sort_by_variable2.max().values)\n",
    "            else:\n",
    "                if minmaxrange2[0] > sort_by_variable2.min().values:\n",
    "                    print(\"Warning: Given minimum value is greater than the minimum value of the variable.\")\n",
    "                    print(\"Warning: Given {}, minmum value of variable {}\".format(minmaxrange2[0],\n",
    "                                                                         sort_by_variable2.min().values))\n",
    "                if minmaxrange2[-1] < sort_by_variable2.max().values:\n",
    "                    print(\"Warning: Given maximum value is smaller than the maximum value of the variable.\")\n",
    "                    print(\"Warning: Given {}, maximum value of variable {}\".format(minmaxrange2[-1],\n",
    "                                                                         sort_by_variable2.max().values))\n",
    "                if type(minmaxrange2) != \"numpy.ndarray\" and type(minmaxrange2) is not tuple:\n",
    "                    print(\"Please provide array range, e.g. np.arange(0,10), or a tuple, e.g. (0,10).\")\n",
    "                else:    \n",
    "                    varmin2 = minmaxrange2[0]\n",
    "                    varmax2 = minmaxrange2[-1]\n",
    "\n",
    "            if N is None:\n",
    "                N = 1024\n",
    "                logger.info(\"Setting N to default value of 1024\")\n",
    "\n",
    "            if type(minmaxrange) == \"numpy.ndarray\":\n",
    "                print('Using provided numpy array for variable 1')\n",
    "\n",
    "                var_q = minmaxrange\n",
    "\n",
    "                #check if equidistant\n",
    "                diff=np.diff(np.diff(var_q))\n",
    "                if len(diff[diff!=0]) != 0:\n",
    "                    print('Warning: Provided array for variable1 is not equidistant, but the function assumes equidistance!')\n",
    "                delta_var=var_q[1]-var_q[0]\n",
    "\n",
    "                var_Q = np.arange(var_q-0.5*delta_var, var_q[-1]+0.5*delta_var, delta_var)\n",
    "            else:\n",
    "                #construct1024ing\n",
    "                delta_var = ((varmax-varmin)/N)           \n",
    "                var_q = np.linspace(varmin + 0.5*delta_var,\n",
    "                                    varmax - 0.5*delta_var,\n",
    "                                    N)                           \n",
    "                var_Q = np.linspace(varmin, varmax, N+1)\n",
    "                \n",
    "            if type(minmaxrange2) == \"numpy.ndarray\":\n",
    "                print('Using provided numpy array for variable 2')\n",
    "\n",
    "                var_q2 = minmaxrange2\n",
    "\n",
    "                #check if equidistant\n",
    "                diff=np.diff(np.diff(var_q2))\n",
    "                if len(diff[diff!=0]) != 0:\n",
    "                    print('Warning: Provided array for variable2 is not equidistant, but the function assumes equidistance!')\n",
    "                delta_var2=var_q2[1]-var_q2[0]\n",
    "        \n",
    "                var_Q2 = np.arange(var_q2-0.5*delta_var2, var_q2[-1]+0.5*delta_var2, delta_var2)\n",
    "            else:\n",
    "                #contructing\n",
    "                delta_var2 = ((varmax2-varmin2)/N)\n",
    "                var_q2 = np.linspace(varmin2 + 0.5*delta_var2,\n",
    "                                     varmax2 - 0.5*delta_var2,\n",
    "                                     N)\n",
    "                var_Q2 = np.linspace(varmin2, varmax2, N+1)\n",
    "            \n",
    "            #sorting\n",
    "            idx = xr.apply_ufunc(np.digitize, sort_by_variable, var_q)\n",
    "            idy = xr.apply_ufunc(np.digitize, sort_by_variable2, var_q2)\n",
    "\n",
    "            out_q = np.zeros((self.timesteps,N, N))\n",
    "\n",
    "            for i in range(N):\n",
    "                for j in range(N):\n",
    "                    out_q[:, i, j] = transport.where((idx == i) & (idy == j)).sum([self._get_name_depth(),\n",
    "                                                                              self._get_name_latitude(),\n",
    "                                                                              self._get_name_longitude()]) / delta_var / delta_var2\n",
    "\n",
    "            out_Q = np.zeros((self.timesteps, N+1, N+1))\n",
    "\n",
    "            for i in range(N):\n",
    "                for j in range(N):\n",
    "                    out_Q[:, i, j] = np.sum(out_q[:, i:, j:] * delta_var * delta_var2)\n",
    "\n",
    "\n",
    "            out = xr.Dataset({\n",
    "            \"q2\": ([\"time\", \"var_q\", \"var_q2\"], out_q),\n",
    "            \"Q2\": ([\"time\", \"var_Q\", \"var_Q2\"], out_Q)},\n",
    "            coords={\n",
    "                \"time\": ([\"time\"], self.ds[self._get_name_time()]),\n",
    "                \"var_q\": ([\"var_q\"],var_q),\n",
    "                \"var_q2\": ([\"var_q2\"], var_q2),\n",
    "                \"var_Q\": ([\"var_Q\"], var_Q),\n",
    "                \"var_Q2\": ([\"var_Q2\"], var_Q2),\n",
    "            })\n",
    "\n",
    "            return out\n",
    "        \n",
    "    def calc_bulk_values(self,\n",
    "                         coord,\n",
    "                         Q,\n",
    "                         Q_thresh=None,\n",
    "                         **kwargs):\n",
    "        \n",
    "        coord_min=coord[0]\n",
    "        delta_var=coord[1]-coord[0]\n",
    "\n",
    "        if Q_thresh is None:\n",
    "            #set a default thresh\n",
    "            Q_thresh=0.01*np.max(np.abs(Q))\n",
    "\n",
    "        if len(Q.shape) > 1:\n",
    "            #first dimension is time! -> keep this dimension!\n",
    "            #prepare storage arrays for Qin, Qout, consider multiple inflow/outflows! \n",
    "            \n",
    "            Qin_ar = np.zeros((Q.shape[0],10)) #10 is the dummy length\n",
    "            Qout_ar = np.zeros((Q.shape[0],10))\n",
    "            divval_ar = np.zeros((Q.shape[0],11)) #if there are 10 transports there would be 11 dividing salinities\n",
    "\n",
    "            for t in np.arange(Q.shape[0]):\n",
    "                ind,minmax = self._find_extrema(Q[t],Q_thresh)\n",
    "\n",
    "                div_val=[]\n",
    "                i=0\n",
    "                for i in range(len(ind)):\n",
    "                    div_val.append(coord_min+delta_var*ind[i])\n",
    "                    i+=1\n",
    "                    #calculate transports etc.\n",
    "                Q_in_m=[]\n",
    "                Q_out_m=[]\n",
    "                index=[]\n",
    "                i=0\n",
    "                for i in range(len(ind)-1):\n",
    "                    Q_i=-(Q[ind[i+1]]-Q[ind[i]])\n",
    "                    if Q_i<0:\n",
    "                        Q_out_m.append(Q_i)\n",
    "                    elif Q_i > 0:\n",
    "                        Q_in_m.append(Q_i)\n",
    "                    else:\n",
    "                        index.append(i)\n",
    "                    i+=1\n",
    "                div_val = np.delete(div_val, index)\n",
    "\n",
    "                #storing results\n",
    "                for i,qq in enumerate(Q_in_m):\n",
    "                    Qin_ar[t,i] = qq\n",
    "                for i,qq in enumerate(Q_out_m):\n",
    "                    Qout_ar[t,i] = qq\n",
    "                for i,ss in enumerate(div_sal):\n",
    "                    divval_ar[t,i] = ss\n",
    "        \n",
    "            #create a xarray Dataset for the results\n",
    "            out = xr.Dataset(\n",
    "            {\n",
    "                \"Qin\": ([\"time\", \"m\"], np.array(Qin_ar)),\n",
    "                \"Qout\": ([\"time\", \"n\"], np.array(Qout_ar)),\n",
    "                \"divval\": ([\"time\", \"o\"], np.array(divval_ar)),\n",
    "            },\n",
    "            coords={\n",
    "                \"time\": ([\"time\"],self.ds[self._get_name_time()]),\n",
    "                \"m\": ([\"m\"],np.arange(len(Qin_ar))),\n",
    "                \"n\": ([\"n\"],np.arange(len(Qout_ar))),\n",
    "                \"o\": ([\"o\"],np.arange(len(divval_ar))),\n",
    "            },\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            #no time axis\n",
    "            ind,minmax = self._find_extrema(Q,Q_thresh)\n",
    "            div_val=[]\n",
    "            i=0\n",
    "            while i < len(ind):\n",
    "                    #print(Qvl[ind[i]])\n",
    "                div_val.append(coord_min+delta_var*ind[i])\n",
    "                i+=1\n",
    "                    #print(smin+dss*ind[i])\n",
    "                #calculate transports etc.\n",
    "            Q_in_m=[]\n",
    "            Q_out_m=[]\n",
    "            index=[]\n",
    "            i=0\n",
    "            for i in range(len(ind)-1):\n",
    "                Q_i=-(Q[ind[i+1]]-Q[ind[i]])\n",
    "                if Q_i<0:\n",
    "                    Q_out_m.append(Q_i)\n",
    "                elif Q_i > 0:\n",
    "                    Q_in_m.append(Q_i)\n",
    "                else:\n",
    "                    index.append(i)\n",
    "                i+=1\n",
    "            div_val = np.delete(div_val, index)\n",
    "            \n",
    "            out = xr.Dataset(\n",
    "            {\n",
    "                \"Qin\": ([\"m\"], np.array(Q_in_m)),\n",
    "                \"Qout\": ([\"n\"], np.array(Q_out_m)),\n",
    "                \"divval\": ([\"o\"], np.array(div_val)),\n",
    "            },\n",
    "            coords={\n",
    "                \"m\": ([\"m\"],np.arange(len(Q_in_m))),\n",
    "                \"n\": ([\"n\"],np.arange(len(Q_out_m))),\n",
    "                \"o\": ([\"o\"],np.arange(len(div_val))),\n",
    "            }\n",
    "            )\n",
    "        return(out)\n",
    "        \n",
    "        \n",
    "    def _find_extrema(self,x,min_transport):\n",
    "        \"\"\"\n",
    "        internal function called by calc_bulk values to find the extrema in the transport function x\n",
    "        and label them correctly\n",
    "        x: Q(S)\n",
    "        min_transport: Q_thresh\n",
    "        \"\"\"\n",
    "        if np.count_nonzero(x)==0:\n",
    "            indices=[0]\n",
    "            minmax=[0]\n",
    "            return(indices,minmax)\n",
    "        else:\n",
    "            ###\n",
    "            #set a minimum value to get rid of numerical noise\n",
    "            ###\n",
    "            if min_transport<=10**(-10):\n",
    "                min_transport=10**(-10)\n",
    "\n",
    "            ####\n",
    "            #finding all extrema by evaluating each data point\n",
    "            ####\n",
    "            comp=1\n",
    "            indices = []\n",
    "            minmax = []\n",
    "            i = 0\n",
    "            while i < np.shape(x)[0]:\n",
    "                if i-comp < 0:\n",
    "                    a = 0\n",
    "                else:\n",
    "                    a=i-comp\n",
    "                if i+comp+1>=len(x):\n",
    "                    b=None\n",
    "                    #c=i\n",
    "                else:\n",
    "                    b=i+comp+1\n",
    "                    #c=b\n",
    "                if x[i] == np.max(x[a:b]) and np.max(x[a:b]) != np.min(x[a:b]):# and x[i] != x[a]:\n",
    "                    indices.append(i)\n",
    "                    minmax.append('max')\n",
    "                elif x[i] == np.min(x[a:b]) and np.max(x[a:b]) != np.min(x[a:b]):# and (x[i] != x[c] or x[i] != x[a]):\n",
    "                    indices.append(i)\n",
    "                    minmax.append('min')\n",
    "                i+=1\n",
    "            #print(indices,minmax)\n",
    "            #print(x[indices])\n",
    "\n",
    "            ###\n",
    "            #correct consecutive extrema of the same kind, e.g., min min min or max max max (especially in the beginning and end of the salinity array)\n",
    "            ###\n",
    "\n",
    "            #index=[]\n",
    "            ii=1\n",
    "            while ii < len(indices):\n",
    "                #print('minmin/maxmax',ii,len(indices))\n",
    "                #print(minmax)\n",
    "                index=[]\n",
    "                if minmax[ii] == minmax[ii-1]:\n",
    "                    if minmax[ii] == 'max': #note the index of the smaller maximum\n",
    "                        if x[indices[ii]]>=x[indices[ii-1]]:\n",
    "                            index.append(ii-1)\n",
    "                        else:\n",
    "                            index.append(ii)\n",
    "                    elif minmax[ii] == 'min': #note the index of the greater minimum\n",
    "                        if x[indices[ii]]<=x[indices[ii-1]]:\n",
    "                            index.append(ii-1)\n",
    "                        else:\n",
    "                            index.append(ii)\n",
    "                    minmax = np.asarray(minmax)\n",
    "                    indices = np.asarray(indices)\n",
    "                    indices = np.delete(indices, index)\n",
    "                    minmax = np.delete(minmax, index)\n",
    "                else:\n",
    "                    ii+=1\n",
    "            #print(indices,minmax)\n",
    "\n",
    "            ####\n",
    "            #delete too small transports\n",
    "            ####\n",
    "\n",
    "            #print(indices,minmax)\n",
    "            ii=0\n",
    "            while ii < len(indices)-1: \n",
    "                index=[]\n",
    "                #print('min_trans',ii,len(indices))\n",
    "                #print(indices,minmax)\n",
    "                #print(np.abs(np.abs(x[indices[ii+1]])-np.abs(x[indices[ii]])),min_transport,indices[ii],indices[ii+1])\n",
    "                if np.abs(x[indices[ii+1]]-x[indices[ii]]) < min_transport:\n",
    "                    #print(np.abs(x[indices[ii+1]]-x[indices[ii]]),min_transport,indices[ii],indices[ii+1],x[indices[ii]],x[indices[ii+1]])\n",
    "                    if ii == 0: #if smin is involved and the transport is too small, smin has to change its min or max property\n",
    "                        #print('if')\n",
    "                        index.append(ii+1)\n",
    "                        if minmax[ii] == 'min':\n",
    "                            minmax[ii] = 'max'\n",
    "                        else:\n",
    "                            minmax[ii] = 'min'\n",
    "                    elif ii+1==len(indices)-1:#if smax is involved and the transport is too small, smin has to change its min or max property\n",
    "                        #print('elif')\n",
    "                        index.append(ii)\n",
    "                        if minmax[ii+1] == 'min':\n",
    "                            minmax[ii+1] = 'max'\n",
    "                        else:\n",
    "                            minmax[ii+1] = 'min'\n",
    "                    else: #else both involved div sals are kicked out\n",
    "                        #print('else')\n",
    "                        if ii+2 < len(indices)-1:\n",
    "                        #check and compare to i+2\n",
    "                            if minmax[ii]=='min':\n",
    "                                if x[indices[ii+2]]>x[indices[ii]]:\n",
    "                                    index.append(ii+2)\n",
    "                                    index.append(ii+1)\n",
    "                                else:\n",
    "                                    index.append(ii)\n",
    "                                    index.append(ii+1)\n",
    "                            elif minmax[ii]=='max':\n",
    "                                if x[indices[ii+2]]<x[indices[ii]]:\n",
    "                                    index.append(ii+2)\n",
    "                                    index.append(ii+1)\n",
    "                                else:\n",
    "                                    index.append(ii)\n",
    "                                    index.append(ii+1)\n",
    "                        else:\n",
    "                            index.append(ii)\n",
    "                            index.append(ii+1)\n",
    "                    #print(index)\n",
    "                    indices = np.delete(indices, index)\n",
    "                    minmax = np.delete(minmax, index)\n",
    "                    #print('after delete',indices,minmax)\n",
    "                else:\n",
    "                    ii+=1\n",
    "\n",
    "            ###\n",
    "            #so far the first and last minmax does not correspond to smin and smax of the data, expecially smin due to numerical errors (only makes sense)\n",
    "            #correct smin index\n",
    "            ###\n",
    "\n",
    "            #print(indices,minmax)\n",
    "            if len(x)>4:\n",
    "                ii=1\n",
    "                while np.abs(np.abs(x[ii])-np.abs(x[0])) < 10**(-10) and ii < len(x)-1:\n",
    "                    ii+=1\n",
    "                indices[0]=ii-1\n",
    "                #correct smax index\n",
    "                if x[-1]==0: #for low salinity classes Q[-1] might not be zero as supposed.\n",
    "                    jj=-1\n",
    "                    while x[jj] == 0 and np.abs(jj) < len(x)-1:\n",
    "                        jj -=1\n",
    "                    indices[-1] = len(x)+jj+1\n",
    "            return indices,minmax\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('/silor/lorenz/packages/pyTEF/')\n",
    "sys.path.append('/fast/lorenz/Programs/tef/tef/')\n",
    "\n",
    "import pyTEF\n",
    "from tef_minimal import *\n",
    "\n",
    "ds = xr.open_dataset(\"/fast/lorenz/pyTEF_data/SoH_2_2011_01.nc\").isel(time=0)\n",
    "\n",
    "tef = TEF_object(ds = ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tef.ds.salt.time.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All variables have to be in the xarray dataset. \n",
    "variable konsistent benennen\n",
    "schichtdicke nicht depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 51, 1) (40, 51, 1)\n",
      "salt_value [-- 38.90345001220703 38.62539291381836 38.81140899658203\n",
      " 38.86116027832031 38.86954879760742 38.745121002197266 38.64644241333008\n",
      " 38.49055862426758 38.31542205810547 37.95930862426758 37.537227630615234\n",
      " 37.56583786010742 37.61852264404297 37.578426361083984 37.566993713378906\n",
      " 37.58642578125 37.67539596557617 37.797122955322266 37.870853424072266\n",
      " 37.89945983886719 37.915550231933594 37.926719665527344\n",
      " 37.922157287597656 37.913387298583984 37.924598693847656\n",
      " 37.933284759521484 37.932037353515625 37.92914962768555 -- -- --\n",
      " 37.89762496948242 37.910011291503906 37.93498992919922 37.93916320800781\n",
      " 37.93860626220703 37.945186614990234 37.94791793823242 37.94742202758789\n",
      " 37.942115783691406 37.93639373779297 37.92705535888672 37.914459228515625\n",
      " 37.90989303588867 37.92158508300781 37.94186019897461 37.95268249511719\n",
      " 37.95315933227539 37.948299407958984 --]\n",
      "idx <xarray.DataArray 'salt' (latc: 51)>\n",
      "array([1025,  595,  538,  576,  586,  588,  563,  542,  511,  475,  402,\n",
      "        315,  321,  332,  324,  321,  325,  344,  369,  384,  390,  393,\n",
      "        395,  394,  392,  395,  396,  396,  396, 1025, 1025, 1025,  389,\n",
      "        392,  397,  398,  398,  399,  399,  399,  398,  397,  395,  393,\n",
      "        392,  394,  398,  400,  401,  400, 1025])\n",
      "Coordinates:\n",
      "  * latc     (latc) float64 26.37 26.38 26.4 26.42 ... 27.15 27.17 27.18 27.2\n",
      "    level    float64 21.0\n",
      "    lonc     float64 56.38\n",
      "    time     datetime64[ns] 2011-01-01T01:00:00\n",
      "idx_old [-- 595 538 576 586 588 563 542 511 475 402 315 321 332 324 321 325 344\n",
      " 369 384 390 393 395 394 392 395 396 396 396 -- -- -- 389 392 397 398 398\n",
      " 399 399 399 398 397 395 393 392 394 398 400 401 400 --]\n",
      "<xarray.DataArray 'salt' ()>\n",
      "array(1025)\n",
      "Coordinates:\n",
      "    time     datetime64[ns] 2011-01-01T01:00:00 809\n",
      "(40, 51, 1) (40, 51, 1)\n",
      "salt_value [-- 38.90345001220703 38.62539291381836 38.81140899658203\n",
      " 38.86116027832031 38.86954879760742 38.745121002197266 38.64644241333008\n",
      " 38.49055862426758 38.31542205810547 37.95930862426758 37.537227630615234\n",
      " 37.56583786010742 37.61852264404297 37.578426361083984 37.566993713378906\n",
      " 37.58642578125 37.67539596557617 37.797122955322266 37.870853424072266\n",
      " 37.89945983886719 37.915550231933594 37.926719665527344\n",
      " 37.922157287597656 37.913387298583984 37.924598693847656\n",
      " 37.933284759521484 37.932037353515625 37.92914962768555 -- -- --\n",
      " 37.89762496948242 37.910011291503906 37.93498992919922 37.93916320800781\n",
      " 37.93860626220703 37.945186614990234 37.94791793823242 37.94742202758789\n",
      " 37.942115783691406 37.93639373779297 37.92705535888672 37.914459228515625\n",
      " 37.90989303588867 37.92158508300781 37.94186019897461 37.95268249511719\n",
      " 37.95315933227539 37.948299407958984 --]\n",
      "idx <xarray.DataArray 'salt' (latc: 51)>\n",
      "array([1025,  595,  538,  576,  586,  588,  563,  542,  511,  475,  402,\n",
      "        315,  321,  332,  324,  321,  325,  344,  369,  384,  390,  393,\n",
      "        395,  394,  392,  395,  396,  396,  396, 1025, 1025, 1025,  389,\n",
      "        392,  397,  398,  398,  399,  399,  399,  398,  397,  395,  393,\n",
      "        392,  394,  398,  400,  401,  400, 1025])\n",
      "Coordinates:\n",
      "  * latc     (latc) float64 26.37 26.38 26.4 26.42 ... 27.15 27.17 27.18 27.2\n",
      "    level    float64 21.0\n",
      "    lonc     float64 56.38\n",
      "    time     datetime64[ns] 2011-01-01T01:00:00\n",
      "idx_old [-- 595 538 576 586 588 563 542 511 475 402 315 321 332 324 321 325 344\n",
      " 369 384 390 393 395 394 392 395 396 396 396 -- -- -- 389 392 397 398 398\n",
      " 399 399 399 398 397 395 393 392 394 398 400 401 400 --]\n",
      "<xarray.DataArray 'salt' ()>\n",
      "array(1025)\n",
      "Coordinates:\n",
      "    time     datetime64[ns] 2011-01-01T01:00:00 809\n"
     ]
    }
   ],
   "source": [
    "tef.calc_volume_transport(-tef.ds.velx3d, tef.ds.hn, tef.ds.dyc)\n",
    "tef.calc_salt_transport(tef.ds.salt,-tef.ds.velx3d, tef.ds.hn, tef.ds.dyc)\n",
    "out = tef.sort_1dim(tef.ds.salt,\n",
    "                  transport = tef.volume_transport,\n",
    "                  N=1024,\n",
    "                  minmaxrange=(36.0,41.0))\n",
    "out2 = tef.sort_1dim(tef.ds.salt,\n",
    "                  transport = tef.salt_transport,\n",
    "                  N=1024,\n",
    "                  minmaxrange=(36.0,41.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38 39 40 41]\n",
      "[36.18798828 36.19287109 36.19775391 36.20263672]\n",
      "[36.18554688 36.19042969 36.1953125  36.20019531 36.20507812]\n"
     ]
    }
   ],
   "source": [
    "print(np.arange(38,42))\n",
    "print(out.var_q.values[38:42])\n",
    "print(out.var_Q.values[38:43])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (m: 1, n: 0, o: 2)\n",
      "Coordinates:\n",
      "  * m        (m) int64 0\n",
      "  * n        (n) int64 \n",
      "  * o        (o) int64 0 1\n",
      "Data variables:\n",
      "    Qin      (m) float64 1.193e+06\n",
      "    Qout     (n) float64 \n",
      "    divval   (o) float64 37.48 39.96\n",
      "<xarray.DataArray 'Qin' (m: 1)>\n",
      "array([1193472.41905785])\n",
      "Coordinates:\n",
      "  * m        (m) int64 0 <xarray.DataArray 'Qout' (n: 0)>\n",
      "array([], dtype=float64)\n",
      "Coordinates:\n",
      "  * n        (n) int64  <xarray.DataArray 'Qin' (m: 1)>\n",
      "array([5.64628213])\n",
      "Coordinates:\n",
      "  * m        (m) int64 0 <xarray.DataArray 'Qout' (n: 0)>\n",
      "array([], dtype=float64)\n",
      "Coordinates:\n",
      "  * n        (n) int64 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compute bulk values\n",
    "#Q_mean = out.Q.mean(axis=0)\n",
    "bulk = tef.calc_bulk_values(out.var_Q,out.Q)\n",
    "print(bulk)\n",
    "#out.q.mean('time').plot()\n",
    "#Q_test = np.cumsum(out.q.mean('time'))*(out.var_q[1]-out.var_q[0])\n",
    "#Qs_test = np.cumsum(out2.q.mean('time'))*(out.var_q[1]-out.var_q[0])\n",
    "\n",
    "out_Q = np.zeros((out.q.shape[0]+1,))\n",
    "out_Qs = np.zeros((out.q.shape[0]+1,))\n",
    "for i in range(out.q.shape[0]):\n",
    "    out_Q[i] = np.sum(out.q[i:] * (out.var_q[1]-out.var_q[0]))\n",
    "    out_Qs[i] = np.sum(out2.q[i:] * (out2.var_q[1]-out2.var_q[0]))\n",
    "\n",
    "plt.plot(out.var_Q,out_Q)\n",
    "bulk2 = tef.calc_bulk_values(out.var_Q,out_Q)\n",
    "bulk3 = tef.calc_bulk_values(out.var_Q,Qs_test)\n",
    "print(bulk2.Qin,bulk2.Qout,bulk3.Qin/bulk2.Qin,bulk3.Qout/bulk2.Qout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.99755859375\n",
      "[-- 144.45501708984375 1176.964111328125 2063.685546875 2531.579345703125\n",
      " 2105.779296875 1448.128662109375 -30.778581619262695 165.74916076660156\n",
      " 811.096435546875 894.5535888671875 804.28564453125 730.6036376953125\n",
      " 746.4135131835938 915.9716186523438 1055.2415771484375 863.4462280273438\n",
      " 535.5344848632812 253.76199340820312 309.8282470703125 1106.4957275390625\n",
      " 1275.769775390625 1231.182861328125 1269.9990234375 1286.3858642578125\n",
      " 1168.32275390625 823.6470947265625 386.047607421875 47.352779388427734 --\n",
      " -- -- 106.32363891601562 354.88360595703125 508.2290954589844\n",
      " 573.1923217773438 572.0330200195312 539.1385498046875 489.4520568847656\n",
      " 386.6741638183594 241.83941650390625 101.41974639892578\n",
      " 38.244972229003906 21.30620574951172 18.67777442932129 18.526369094848633\n",
      " 20.049123764038086 20.996360778808594 19.645544052124023\n",
      " 4.026042461395264 --]\n",
      "input is good\n",
      "tmax 1\n",
      "min_trans 11934.724228871464\n",
      "[304 811] ['max' 'min']\n",
      "[37.48536682 39.95853519]\n",
      "[1193472.4228871465]\n",
      "[]\n",
      "[1193472.4228871465] []\n",
      "[36.00488043 36.00975847 36.01463652 ... 40.98536348 40.99024153\n",
      " 40.99511957] <xarray.DataArray 'var_q' (var_q: 1024)>\n",
      "array([36.002441, 36.007324, 36.012207, ..., 40.987793, 40.992676, 40.997559])\n",
      "Coordinates:\n",
      "  * var_q    (var_q) float64 36.0 36.01 36.01 36.02 ... 40.98 40.99 40.99 41.0\n"
     ]
    }
   ],
   "source": [
    "#compute olf TEF method:\n",
    "s_min=36.0\n",
    "s_max=41.0\n",
    "N=1024\n",
    "DeltaS=(s_max-s_min)/N\n",
    "salt_array=np.arange(s_min+0.5*DeltaS,s_max+0.5*DeltaS,DeltaS)\n",
    "print(salt_array[-1])\n",
    "flux = np.ma.masked_invalid(-ds.velx3d.values*ds.hn.values*ds.dyc.values)\n",
    "salt=np.ma.masked_invalid(ds.salt.values)\n",
    "print(flux[1,:,0])\n",
    "q, Q, sq, sQ = sort_by_salinity_fast(salt,flux,\n",
    "                                                 1024,tmax_auto=1,salinity_array=salt_array)\n",
    "Q_in_m,Q_out_m,div_sal,ind=calc_bulk_values_new(sQ,Q,1,min_trans='auto')\n",
    "print(Q_in_m,Q_out_m)\n",
    "\n",
    "\n",
    "print(sq, out.var_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = tef.sort_2dim(sort_by_variable=tef.ds.salt,\n",
    "                    sort_by_variable2=tef.ds.temp,\n",
    "                    flux = tef.flux,\n",
    "                    N = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.q2.mean(\"time\").plot(x = \"var_q\", y = \"var_q2\", cmap = plt.cm.RdBu_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1)\n",
    "plt.plot(out.q.mean(\"time\").values, out.var_q.values)\n",
    "ax.invert_yaxis()\n",
    "ax.set_ylabel(\"Salinity $[g/kg]$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type((0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'salt' ()>\n",
      "array(36.72302, dtype=float32) <xarray.DataArray 'salt' ()>\n",
      "array(40.469566, dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tef.ds.salt.min(),tef.ds.salt.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(1) Python 3",
   "language": "python",
   "name": "iow_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
